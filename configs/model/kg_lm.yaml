_target_: src.models.lit_module.LitModule

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 0.001
  weight_decay: 0.0

scheduler:
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  _partial_: true
  mode: min
  factor: 0.1
  patience: 10

net:
  _target_: src.models.components.kg_augmented_lm.KGAugmentedLM
  latent_dim: 128
  num_unimodal_encoder_layers: 2
  num_unimodal_encoder_heads: 2
  fusion_model: 'bottleneck'
  bottleneck_width: 4
  num_fusion_layers: 2
  num_fusion_heads: 2
  text_vocab_size: 32768 # wikigraphs: 32768, wikidata5m: 65536
  graph_vocab_size: 8192 # wikigraphs: 8192, wikidata5m: 16384
  num_edge_types: 256 # wikigraphs: 256, wikidata5m: 512
  modality_encoding: 'sinusoidal'